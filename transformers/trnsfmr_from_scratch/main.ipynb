{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0687015-483f-4acb-848a-2f93efe7d510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.nn' from '/Users/bimalmgr/Downloads/deep_learning/transformers/trnsfmr_from_scratch/models/nn.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils.data_loader\n",
    "import utils.tokenize\n",
    "import models.embedding\n",
    "import models.nn\n",
    "\n",
    "#For reloading\n",
    "importlib.reload(utils.data_loader)\n",
    "importlib.reload(utils.tokenize)\n",
    "importlib.reload(models.embedding)\n",
    "importlib.reload(models.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04707c00-2a11-45c3-9b67-addcea9612d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import DataLoader\n",
    "from utils.tokenize import Tokenizer\n",
    "from data import en,es\n",
    "from models.embedding import Embeddings\n",
    "from data import en,es\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5d510d-f35b-4fce-871c-e8f5670499ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_modules():\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2693b3b3-699c-46a5-96dc-7bcbb04dccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the implementation of transformer from scratch in PyTorch.........!!\n",
      "Initializing the data loader........\n",
      "train [{'src': ['<sos>', 'Mi', 'nombre', '<eos>'], 'trg': ['<sos>', 'My', 'name', '<eos>']}, {'src': ['<sos>', 'es', 'Bimal', '!', '!', '<eos>'], 'trg': ['<sos>', 'is', 'Bimal', '!', '!', '<eos>']}] val [] test [{'src': ['<sos>', '@', '1', '23', '*', ';', '.', '<eos>'], 'trg': ['<sos>', '@', '1', '23', '*', ';', '.', '<eos>']}]\n",
      "Building Spanish Vocabulary.....\n",
      "Done Building Spanish Vocabulary!\n",
      "Buidling English Vocabulary.........\n",
      "Done building English Vocabulary!\n",
      "{'Bimal': 11, '23': 8, '1': 7, '.': 6, 'es': 13, '*': 5, '!': 4, ';': 9, '<sos>': 2, 'nombre': 14, 'Mi': 12, '@': 10, '<eos>': 3, '<pad>': 1, '<unk>': 0}\n",
      "{'is': 13, 'Bimal': 11, '23': 8, '1': 7, 'name': 14, '.': 6, '*': 5, '!': 4, ';': 9, '<sos>': 2, '@': 10, '<eos>': 3, 'My': 12, '<pad>': 1, '<unk>': 0}\n",
      "tensor([[ 0.9252,  1.0360, -0.2125, -0.4693,  0.6936],\n",
      "        [-0.3631, -0.0094,  0.5465, -0.2899,  0.5576]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    reload_modules()\n",
    "    print(\"This is the implementation of transformer from scratch in PyTorch.........!!\")\n",
    "    tokenizer = Tokenizer()\n",
    "    data_loader = DataLoader(\n",
    "        tokenize_source=tokenizer.tokenize_source,\n",
    "        tokenize_target=tokenizer.tokenize_target\n",
    "    )\n",
    "    # train_set,valid_set,test_set = data_loader.make_dataset(es,en)\n",
    "    # vocab_src,vocab_trg = data_loader.build_vocab(train_set,valid_set,test_set)\n",
    "    # for word,index in vocab_trg.get_stoi().items():\n",
    "    #     print(word,index)\n",
    "    # print(f\"Tokenized source example: {tokenizer.tokenize_source('Mi nombre es Bimal !! @ 1 23 * ;.')}\")\n",
    "    # print(f\"Tokenized target example: {tokenizer.tokenize_target('My name is Bimal !! @ 1 23 * ;.')}\")\n",
    "    # print(f\"Dataset examples: {data_loader.make_dataset(['Mi nombre es Bimal !! @ 1 23 * ;.'],['My name is Bimal !! @ 1 23 * ;.'])}\")\n",
    "    s_tr,s_v,s_te = data_loader.make_dataset(['Mi nombre ','es Bimal !!','@ 1 23 * ;.'],['My name','is Bimal !!','@ 1 23 * ;.'])\n",
    "    print(\"train\",s_tr,\"val\",s_v,\"test\",s_te)\n",
    "    s_v,s_t = data_loader.build_vocab(s_tr,s_v,s_te)\n",
    "    print(s_v.get_stoi())\n",
    "    print(s_t.get_stoi())\n",
    "    # print(\"Source vobularies:\",vocab_src)\n",
    "    embed = nn.Embedding(len(s_v),5)\n",
    "    print(embed(torch.tensor([s_v.get_stoi()['Bimal'],s_v.get_stoi()['nombre']])))\n",
    "    # print(embed(torch.tensor(vocab_src.get_stoi()['víctimas'])))\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453ead9-cb25-4ff2-a85b-6bdea2cf9a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. PYTORCH VERSION:\n",
      "   Input: tensor([1., 2., 3.])\n",
      "   Output: tensor([ 0.2452, -0.2601], grad_fn=<ViewBackward0>)\n",
      "   Output as list: [0.2451966404914856, -0.2601064145565033]\n",
      "\n",
      "   Output as list: [0.2451966404914856, -0.2601064145565033]\n",
      "\n",
      "  weights: torch.Size([4, 3])\n",
      "\n",
      "3. KEY DIFFERENCES:\n",
      "   From Scratch:\n",
      "   • Manual matrix multiplication\n",
      "   • Manual bias addition\n",
      "   • Manual ReLU implementation\n",
      "   • Lists and basic Python\n",
      "   • Educational - you see every step!\n",
      "\n",
      "   PyTorch:\n",
      "   • Automatic differentiation (for training)\n",
      "   • GPU acceleration\n",
      "   • Optimized operations\n",
      "   • Cleaner, more readable code\n",
      "   • Production ready\n",
      "\n",
      "4. WHAT THEY BOTH DO:\n",
      "   • Learn patterns in data\n",
      "   • Transform input through layers\n",
      "   • Use weights and biases\n",
      "   • Apply activation functions\n",
      "   • Make predictions\n",
      "\n",
      "The math is identical - PyTorch just handles it more efficiently!\n"
     ]
    }
   ],
   "source": [
    "from models.nn import MLPPyTorch\n",
    "\n",
    "input_size, hidden_size, output_size = 3, 4, 2\n",
    "# model_scratch = MLPFromScratch(input_size, hidden_size, output_size)\n",
    "# print(len(model_scratch.W1))\n",
    "# print(len(model_scratch.W2))\n",
    "model_pytorch = MLPPyTorch(input_size, hidden_size, output_size)\n",
    "\n",
    "# # Test input\n",
    "# test_input_list = [1.0, 2.0, 3.0]  # For scratch version\n",
    "# test_input_tensor = torch.tensor([1.0, 2.0, 3.0])  # For PyTorch version\n",
    "\n",
    "# print(\"1. FROM SCRATCH VERSION:\")\n",
    "# print(f\"   Input: {test_input_list}\")\n",
    "\n",
    "# # Show step-by-step for scratch version\n",
    "# print(\"   Step-by-step breakdown:\")\n",
    "\n",
    "# Step 1: Matrix multiplication for layer 1\n",
    "# hidden = model_scratch.matrix_multiply(model_scratch.W1, test_input_list)\n",
    "# hidden = model_scratch.add_bias(hidden, model_scratch.b1)\n",
    "# print(f\"   After layer 1 (before ReLU): {hidden}\")\n",
    "\n",
    "# # Step 2: ReLU activation\n",
    "# hidden = model_scratch.relu(hidden)\n",
    "# print(f\"   After ReLU activation: {hidden}\")\n",
    "\n",
    "# # Step 3: Matrix multiplication for layer 2\n",
    "# output = model_scratch.matrix_multiply(model_scratch.W2, hidden)\n",
    "# output = model_scratch.add_bias(output, model_scratch.b2)\n",
    "# print(f\"   Final output: {output}\")\n",
    "\n",
    "# # Complete forward pass\n",
    "# full_output = model_scratch.forward(test_input_list)\n",
    "# print(f\"   Complete forward pass: {full_output}\\n\")\n",
    "\n",
    "test_input_tensor = torch.tensor([1.0, 2.0, 3.0])  # For PyTorch version\n",
    "print(\"2. PYTORCH VERSION:\")\n",
    "print(f\"   Input: {test_input_tensor}\")\n",
    "output_pytorch = model_pytorch(test_input_tensor)\n",
    "print(f\"   Output: {output_pytorch}\")\n",
    "print(f\"   Output as list: {output_pytorch.tolist()}\\n\")\n",
    "print(f\"   Output as list: {output_pytorch.tolist()}\\n\")\n",
    "print(f\"  weights: {model_pytorch.layer1.weight.shape}\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformer-Scratch",
   "language": "python",
   "name": "trfmr-scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
