{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0687015-483f-4acb-848a-2f93efe7d510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.embedding' from '/Users/bimalmgr/Downloads/deep_learning/transformers/trnsfmr_from_scratch/models/embedding.py'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils.data_loader\n",
    "import utils.tokenize\n",
    "import models.embedding\n",
    "\n",
    "#For reloading\n",
    "importlib.reload(utils.data_loader)\n",
    "importlib.reload(utils.tokenize)\n",
    "importlib.reload(models.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04707c00-2a11-45c3-9b67-addcea9612d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import DataLoader\n",
    "from utils.tokenize import Tokenizer\n",
    "from data import en,es\n",
    "from models.embedding import Embeddings\n",
    "from data import en,es\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c5d510d-f35b-4fce-871c-e8f5670499ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_modules():\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2693b3b3-699c-46a5-96dc-7bcbb04dccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "This is the implementation of transformer from scratch in PyTorch.........!!\n",
      "Initializing the data loader........\n",
      "Building Spanish Vocabulary.....\n",
      "Done Building Spanish Vocabulary!\n",
      "Buidling English Vocabulary.........\n",
      "Done building English Vocabulary!\n",
      "Source vobularies: Vocab()\n",
      "tensor([-0.6753,  0.3612,  0.2072], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    reload_modules()\n",
    "    print(\"This is the implementation of transformer from scratch in PyTorch.........!!\")\n",
    "    tokenizer = Tokenizer()\n",
    "    data_loader = DataLoader(\n",
    "        tokenize_source=tokenizer.tokenize_source,\n",
    "        tokenize_target=tokenizer.tokenize_target\n",
    "    )\n",
    "    train_set,valid_set,test_set = data_loader.make_dataset(es,en)\n",
    "    vocab_src,vocab_trg = data_loader.build_vocab(train_set,valid_set,test_set)\n",
    "    # for word,index in vocab_trg.get_stoi().items():\n",
    "    #     print(word,index)\n",
    "   \n",
    "    print(\"Source vobularies:\",vocab_src)\n",
    "    embed = nn.Embedding(len(vocab_src),3)\n",
    "    print(embed(torch.tensor(vocab_src.get_stoi()['v√≠ctimas'])))\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformer-Scratch",
   "language": "python",
   "name": "trfmr-scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
