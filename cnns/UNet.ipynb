{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLrelOHZ_qZN"
      },
      "outputs": [],
      "source": [
        "# UNet Architecture in Py Torch from scratch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b_81hDNxyLX",
        "outputId": "edc640f2-4a2c-4014-ce55-95a02d8cfd27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hef3QJgBmWIQ",
        "outputId": "790f64c8-7225-4f2c-9ceb-d7956be72865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision.transforms import transforms\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "hyH0wPxUCPa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels,out_channels,kernel_size = 3),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels,out_channels,kernel_size=3),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "MTNk_skXXfWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownSample(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels):\n",
        "    super().__init__()\n",
        "    self.conv = DoubleConv(in_channels,out_channels)\n",
        "    self.pool = nn.MaxPool2d(kernel_size = 2,strid = 2)\n",
        "\n",
        "  def forward(self,x):\n",
        "    down = self.conv(x)\n",
        "    p = self.pool(down)\n",
        "    return down,p"
      ],
      "metadata": {
        "id": "kwpCGUCNaW-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpSample(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels):\n",
        "    super().__init__()\n",
        "    self.up = nn.ConvTranspose2d(in_channels,in_channels // 2,kernel_size=2,stride=2)\n",
        "    self.conv = DoubleConv(in_channels,out_channels)\n",
        "\n",
        "  def forward(self,x1,x2):\n",
        "    x1 = self.up(x1)\n",
        "\n",
        "    x = torch.cat([x1,x2],1)\n",
        "\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "WVDwlVZRjSkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self,in_channels,num_classes):\n",
        "    super().__init__()\n",
        "    self.down_conv1 = DownSample(in_channels,64)\n",
        "    self.down_conv2 = DownSample(64,128)\n",
        "    self.down_conv3 = DownSample(128,256)\n",
        "    self.down_conv4 = DownSample(256,512)\n",
        "\n",
        "\n",
        "    self.bottle_neck = DownSample(512,1024)\n",
        "\n",
        "    self.up_conv1 = UpSample(1024,512)\n",
        "    self.up_conv2 = UpSample(512,256)\n",
        "    self.up_conv3 = UpSample(256,128)\n",
        "    self.up_conv4 = UpSample(128,64)\n",
        "\n",
        "    self.out = nn.Conv2d(64,out_channels=num_classes, kernel_size=1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x1,s1 = self.down_conv1(x)\n",
        "    x2,s2 = self.down_conv2(s1)\n",
        "    x3,s3 = self.down_conv3(s2)\n",
        "    x4,s4 = self.down_conv4(s3)\n",
        "\n",
        "    x5 = self.bottle_neck(s4)\n",
        "\n",
        "    y1 = self.up_conv1(x5,x4)\n",
        "    y2 = self.up_conv2(y1,x3)\n",
        "    y3 = self.up_conv(y2,x2)\n",
        "    y4 = self.up_conv4(y3,x1)\n",
        "\n",
        "    return self.out(y4)"
      ],
      "metadata": {
        "id": "48rAf3Iml_LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CarvanaDataset(Dataset):\n",
        "  def __init__(self,root_path,test=False):\n",
        "    self.root_path = root_path\n",
        "    if test:\n",
        "      self.images = sorted([root_path + \"/test/\" + filename for filename in os.listdir(os.path.join(root_path,\"test/\"))])\n",
        "      self.masks = sorted([root_path + \"/test_masks/\" + filename for filename in os.listdir(os.path.join(root_path,\"test_masks/\"))])\n",
        "    else:\n",
        "      self.images =  sorted([root_path + \"/test/\" + filename for filename in os.listdir(os.path.join(root_path,\"train/\"))])\n",
        "      self.masks = sorted([root_path + \"/train_masks/\" + filename for filename in os.listdir(os.path.join(root_path,\"train_masks/\"))])\n",
        "\n",
        "    self.transform = transforms.Compose([\n",
        "        transforms.Resize((572,572)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "     image = Image.open(self.images[idx]).convert('RGB')\n",
        "     mask = Image.open(self.masks[idx]).convert('L')\n",
        "     return self.transform(image),self.transform(mask)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)"
      ],
      "metadata": {
        "id": "J3WYbHtpxaec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,train_loader,optimizer,criterion,start_epoch,num_epochs,MODEL_SAVE_PATH,device):\n",
        "  for epoch in tqdm(range(start_epoch,num_epochs)):\n",
        "      model.train()\n",
        "      train_running_loss = 0.0\n",
        "      best_loss = float('inf')\n",
        "      for idx,img_mask in enumerate(tqdm(train_loader)):\n",
        "          img = img_mask[0].to(device)\n",
        "          mask = img_mask[1].to(device)\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          output = model(img)\n",
        "\n",
        "          loss = criterion(output,mask)\n",
        "          train_running_loss += loss.item()\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "      train_loss = train_running_loss / len(train_loader)\n",
        "\n",
        "\n",
        "      model.eval()\n",
        "      val_running_loss = 0.0\n",
        "      with torch.no_grad():\n",
        "        for idx,img_mask in enumerate(tqdm(val_loader)):\n",
        "          img = img_mask[0].float().to(device)\n",
        "          mask = img_mask[1].float().to(device)\n",
        "\n",
        "          output = model(img)\n",
        "\n",
        "          loss = criterion(output,mask)\n",
        "\n",
        "          val_running_loss += loss.item()\n",
        "        val_loss = val_running_loss / len(val_loader)\n",
        "\n",
        "      print(\"-\" * 30)\n",
        "      print(f\"EPOCH:{epoch + 1}, Train Loss:{train_loss:.4f}, Val Loss:{val_loss:.4f}\")\n",
        "      print(\"-\" * 30)\n",
        "\n",
        "      if(val_loss < best_loss):\n",
        "        best_loss = val_loss\n",
        "        torch.save({\n",
        "            \"epoch\":\"epoch\",\n",
        "            \"model_state_dict\":model.state_dict(),\n",
        "            \"optimizer_state_dict\":optimizer.state_dict(),\n",
        "            \"loss\":val_loss\n",
        "        },MODEL_SAVE_PATH + \"model.pth\")\n",
        "        print(f\"Model saved at EPOCH {epoch+1} with loss {best_loss:.4f}\")\n",
        "      else:\n",
        "        print(f\"Skipping save at epoch {epoch+1} with loss did not improve\")\n",
        "\n"
      ],
      "metadata": {
        "id": "c1MKlVx87ypQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(model,optimizer,CHECKPOINT_PATH):\n",
        "  checkpoint = torch.load(CHECKPOINT_PATH)\n",
        "  model.load_state_dict(checkpoint(\"model_state_dict\"))\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  start_epoch = checkpoint['epoch']\n",
        "\n",
        "  print(f\"Resuming from epoch {start_epoch}, Best Loss was :{checkpoint['loss']:.4f}\")\n",
        "\n",
        "  return start_epoch"
      ],
      "metadata": {
        "id": "Ti6GXxyuBYj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image_grid(model,root_path,device):\n",
        "  image_dataset = CarvanaDataset(root_path,test=True)\n",
        "  # test_loader = DataLoader(image_dataset,batch_size=BATCH_SIZE,shuffle=False)\n",
        "  images = []\n",
        "  original_masks = []\n",
        "  predicted_masks = []\n",
        "\n",
        "  for img,original_mask in image_dataset:\n",
        "    img = img.float().to(device)\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    pred_mask = model(img)\n",
        "\n",
        "    img = img.squeeze(0).cpu().detach()\n",
        "    img = img.permute(1,2,0)\n",
        "\n",
        "    pred_mask = pred_mask.squeeze(0).cpu().detach()\n",
        "    pred_mask = pred_mask.permute(1,2,0)\n",
        "    pred_mask[pred_mask < 0] = 0\n",
        "    pred_mask[pred_mask > 1] = 1\n",
        "\n",
        "    original_mask = original_mask.cpu().detach()\n",
        "    original_mask = original_mask.permute(1,2,0)\n",
        "\n",
        "    images.append(img)\n",
        "    original_masks.append(original_mask)\n",
        "    predicted_masks.append(pred_mask)\n",
        "  images.extend(original_masks)\n",
        "  images.extend(predicted_masks)\n",
        "\n",
        "  fig = plt.figure()\n",
        "  for i in range(1, 3*len(image_dataset)+1):\n",
        "    fig.add_subplots(3,len(image_dataset),i)\n",
        "    plt.imshow(images[i-1],cmap=\"gray\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "S18WTDEdORWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def single_image_inference(model,image_path,device):\n",
        "  transform = transforms.Compose([\n",
        "    transforms.Resize((572,572)),\n",
        "    transforms.ToTensor()\n",
        "  ])\n",
        "\n",
        "  img = transform(Image.open(image_path)).float().to(device)\n",
        "  img = img.unsqueeze(0)\n",
        "\n",
        "  pred_mask = model(img)\n",
        "\n",
        "  img = img.squeeze(0).cpu().detach()\n",
        "  img = img.permute(1,2,0)\n",
        "\n",
        "  pred_mask = pred_mask.squeeze(0).cpu().detach()\n",
        "  pred_mask = pred_mask.permute(1,2,0)\n",
        "  pred_mask[pred_mask < 0] = 0\n",
        "  pred_mask[pred_mask > 1] = 1\n",
        "\n",
        "  fig = plt.figure()\n",
        "  for i in range(1,3):\n",
        "    fig.add_subplot(1,2,i)\n",
        "    if i == 1:\n",
        "      plt.imshow(img,cmap=\"gray\")\n",
        "    else:\n",
        "      plt.imshow(pred_mask,cmap=\"gray\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "VLeV1BIMJfmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 3e-4 #0.0003\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 2\n",
        "DATA_PATH = \"./drive/MyDrive/unet-datasets/\"\n",
        "MODEL_SAVE_PATH =\"./drive/MyDrive/unet-datasets/model-checkpoints/\"\n",
        "\n",
        "SINGLE_PATH_IMAGE = \"./drive/MyDrive/unet-datasets/29bb3ece3180_11.jpg\"\n",
        "\n",
        "device = torch.device = \"cuda\" if torch.cude.is_available else \"cpu\"\n",
        "\n",
        "train_dataset = CarvanaDataset(DATA_PATH)\n",
        "\n",
        "g = torch.Generator().manual_seed(42)\n",
        "train_dataset,val_dataset = random_split(train_dataset,[int(0.8*len(train_dataset)),int(0.2*len(train_dataset))],generator=g)\n",
        "\n",
        "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
        "val_loader = DataLoader(val_dataset,batch_size = BATCH_SIZE,shuffle=True)\n",
        "\n",
        "\n",
        "model = UNet(in_channels=3,num_classes=1).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(),lr=LEARNING_RATE)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "9wSAo7PfsCM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if os.path.exists(MODEL_SAVE_PATH + \"model.pth\"):\n",
        "  start_epoch = load_checkpoint(model,optimizer,MODEL_SAVE_PATH)\n",
        "else:\n",
        "  start_epoch = 0\n",
        "\n",
        "train(model,train_loader,optimizer,criterion,start_epoch,EPOCHS,MODEL_SAVE_PATH,device)"
      ],
      "metadata": {
        "id": "_FluZVGTBJ-J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}