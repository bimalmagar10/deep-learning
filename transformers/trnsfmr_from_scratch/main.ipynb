{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0687015-483f-4acb-848a-2f93efe7d510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randiko Baan!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'models.nn' from 'C:\\\\Users\\\\bthapama\\\\Downloads\\\\projects\\\\deep-learning\\\\transformers\\\\trnsfmr_from_scratch\\\\models\\\\nn.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils.data_loader\n",
    "import utils.tokenize\n",
    "import models.embedding\n",
    "import models.nn\n",
    "\n",
    "#For reloading\n",
    "importlib.reload(utils.data_loader)\n",
    "importlib.reload(utils.tokenize)\n",
    "importlib.reload(models.embedding)\n",
    "importlib.reload(models.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04707c00-2a11-45c3-9b67-addcea9612d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import DataLoader\n",
    "from utils.tokenize import Tokenizer\n",
    "from data import en,es\n",
    "from models.embedding import Embeddings\n",
    "from data import en,es\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c5d510d-f35b-4fce-871c-e8f5670499ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_modules():\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693b3b3-699c-46a5-96dc-7bcbb04dccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "This is the implementation of transformer from scratch in PyTorch.........!!\n",
      "Initializing the data loader........\n",
      "Building Spanish Vocabulary.....\n",
      "Done Building Spanish Vocabulary!\n",
      "Buidling English Vocabulary.........\n",
      "Done building English Vocabulary!\n",
      ". 7\n",
      "<unk> 0\n",
      "<eos> 3\n",
      "<pad> 1\n",
      "the 5\n",
      "to 9\n",
      "<sos> 2\n",
      ", 4\n",
      "of 6\n",
      "a 8\n",
      "tensor([[ 5.5749e-01, -7.8865e-01, -2.7708e-01, -2.3291e-01, -8.4945e-01],\n",
      "        [-2.1066e+00,  5.9075e-01,  1.2459e-03, -1.1057e-01,  1.7735e-01],\n",
      "        [ 3.1986e-01, -1.0073e+00, -1.7728e+00, -2.7856e-01, -6.9147e-01],\n",
      "        [ 2.0885e+00, -5.9621e-01,  4.5372e-01,  9.8975e-01, -3.3422e-04],\n",
      "        [ 2.7980e-02,  1.5396e+00,  4.8366e-01, -2.8189e-01,  6.3046e-01],\n",
      "        [ 1.4221e+00,  4.7144e-01,  7.2093e-01, -1.0106e+00, -2.3563e+00],\n",
      "        [-1.5583e-01,  2.1003e-01, -7.5314e-01,  1.7781e+00,  2.5860e-01],\n",
      "        [ 9.0732e-02, -1.9098e-01,  9.7097e-01,  8.1745e-01,  7.3396e-02],\n",
      "        [ 1.4331e+00,  1.1388e+00,  4.6457e-01,  9.8689e-01, -4.8434e-01],\n",
      "        [ 2.0885e+00, -5.9621e-01,  4.5372e-01,  9.8975e-01, -3.3422e-04],\n",
      "        [ 2.7980e-02,  1.5396e+00,  4.8366e-01, -2.8189e-01,  6.3046e-01],\n",
      "        [ 1.4221e+00,  4.7144e-01,  7.2093e-01, -1.0106e+00, -2.3563e+00],\n",
      "        [ 3.1986e-01, -1.0073e+00, -1.7728e+00, -2.7856e-01, -6.9147e-01],\n",
      "        [ 3.6172e-01, -8.3837e-02, -1.4776e+00, -1.1119e+00, -1.3511e+00],\n",
      "        [-1.9860e+00, -1.5700e+00, -2.4628e+00,  4.2166e-01,  3.4661e-01],\n",
      "        [-3.7603e-01, -6.6041e-01, -9.2754e-01, -9.7947e-01,  1.7383e-01],\n",
      "        [ 6.2246e-01, -5.6419e-01, -8.0940e-01,  1.7481e-01, -6.6132e-01],\n",
      "        [ 1.4331e+00,  1.1388e+00,  4.6457e-01,  9.8689e-01, -4.8434e-01],\n",
      "        [-3.2118e-01,  1.6971e-01,  3.2596e-01, -5.3028e-01, -7.5103e-01],\n",
      "        [ 3.0358e-01, -1.6714e+00,  1.0546e+00, -5.0703e-01, -4.9419e-01],\n",
      "        [ 2.7980e-02,  1.5396e+00,  4.8366e-01, -2.8189e-01,  6.3046e-01],\n",
      "        [-5.1891e-01, -1.7036e+00, -2.2797e+00,  2.4296e-01,  4.0888e-01],\n",
      "        [ 9.8748e-01,  1.1779e+00,  1.7069e+00,  1.2108e+00,  6.4984e-01],\n",
      "        [-3.7603e-01, -6.6041e-01, -9.2754e-01, -9.7947e-01,  1.7383e-01],\n",
      "        [-5.3286e-02, -1.0319e+00, -1.5964e+00, -2.8422e-01,  5.5791e-01],\n",
      "        [-2.8193e+00,  5.1482e-01,  3.8440e-01, -2.9857e-01, -7.1554e-01],\n",
      "        [ 2.9950e-01,  4.8880e-01,  1.2139e+00, -8.3861e-01, -2.1568e+00],\n",
      "        [-5.9167e-01, -3.2698e-01, -4.1257e-01,  4.8727e-01, -7.1927e-01],\n",
      "        [ 7.2697e-01, -1.8564e+00, -4.5793e-01,  1.6531e+00,  6.0582e-01],\n",
      "        [ 1.1690e+00,  2.3327e-01, -1.7501e+00,  1.2024e+00, -5.7634e-01],\n",
      "        [-3.6797e-01,  3.1224e-01, -1.5070e+00,  1.6528e-01, -1.0258e+00],\n",
      "        [ 2.7980e-02,  1.5396e+00,  4.8366e-01, -2.8189e-01,  6.3046e-01],\n",
      "        [-8.9397e-01, -1.8881e-01, -1.0472e+00, -4.5113e-01,  3.1248e-01],\n",
      "        [ 4.4568e-01, -4.8798e-01, -7.2468e-01,  9.6638e-01,  3.0132e-02],\n",
      "        [-2.5269e-01, -1.7688e-01, -1.4397e+00,  3.3496e-02, -4.8925e-01],\n",
      "        [ 1.5523e-01, -1.5815e+00, -1.3961e+00, -1.1712e+00, -5.7227e-01],\n",
      "        [ 1.2513e+00,  2.1996e+00, -1.1063e+00,  4.1148e-01,  1.1123e+00],\n",
      "        [ 1.4854e+00, -3.2039e-01, -2.6771e+00,  1.9347e-01,  5.1812e-01],\n",
      "        [-5.9763e-01,  9.4276e-01,  2.6251e-01,  2.9478e-01,  1.5380e+00],\n",
      "        [ 1.7554e+00,  2.9009e+00, -1.5138e+00, -1.0331e+00, -9.6869e-02]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "\n",
      "tensor([[ 0.5575, -0.7886, -0.2771, -0.2329, -0.8495],\n",
      "        [ 2.3866, -0.2229,  1.2590,  2.2591, -0.2567],\n",
      "        [-0.8940, -0.1888, -1.0472, -0.4511,  0.3125],\n",
      "        [-0.3760, -0.6604, -0.9275, -0.9795,  0.1738],\n",
      "        [ 0.9332,  0.9924,  2.2838, -0.3383, -0.5021],\n",
      "        [-1.1784, -0.1554, -0.0099, -1.6671,  1.8380],\n",
      "        [-0.1286, -1.6693,  0.9824,  1.4251,  0.3586],\n",
      "        [-1.9612, -0.6669,  0.1919, -0.5549, -0.2468],\n",
      "        [-0.3760, -0.6604, -0.9275, -0.9795,  0.1738],\n",
      "        [ 0.9332,  0.9924,  2.2838, -0.3383, -0.5021],\n",
      "        [-0.8940, -0.1888, -1.0472, -0.4511,  0.3125],\n",
      "        [-0.3760, -0.6604, -0.9275, -0.9795,  0.1738],\n",
      "        [-1.4348, -1.3671,  0.3232,  0.1399,  1.4791],\n",
      "        [-0.3892, -1.8154,  1.7484, -0.9329,  0.5834],\n",
      "        [-0.1303,  0.7687, -0.3263,  0.7057, -0.7025],\n",
      "        [ 2.1944, -0.2486,  0.7047, -0.2840, -0.8930],\n",
      "        [-0.9988,  0.3548,  0.3998,  1.5628,  0.2114],\n",
      "        [-0.1558,  0.2100, -0.7531,  1.7781,  0.2586],\n",
      "        [ 1.2013,  0.5916,  0.7033,  0.5293,  0.5346],\n",
      "        [ 0.9719,  1.4215, -1.3600, -0.6411,  0.0631],\n",
      "        [ 0.0280,  1.5396,  0.4837, -0.2819,  0.6305],\n",
      "        [-0.0533, -1.0319, -1.5964, -0.2842,  0.5579],\n",
      "        [-1.1784, -0.1554, -0.0099, -1.6671,  1.8380],\n",
      "        [-1.6274,  1.5597,  0.0052, -0.3498,  1.0510],\n",
      "        [-2.0995,  1.5715, -1.0062,  0.1664, -0.0424],\n",
      "        [ 0.4971, -0.1640, -0.7471,  0.9702,  1.4295],\n",
      "        [ 1.4120,  0.2780,  0.6985, -0.4808,  0.3360],\n",
      "        [-0.0644,  0.1002,  2.0149, -0.6632, -0.1396],\n",
      "        [-0.8802,  1.0970,  0.5189,  0.2289, -0.7621],\n",
      "        [ 0.3199, -1.0073, -1.7728, -0.2786, -0.6915],\n",
      "        [ 1.4331,  1.1388,  0.4646,  0.9869, -0.4843],\n",
      "        [-0.9944, -1.5272,  0.0902,  1.7662, -1.6873],\n",
      "        [ 1.1346, -0.7231,  1.0934,  1.0871, -0.5774],\n",
      "        [ 0.0095, -0.5113,  1.2272,  0.4887, -0.1558],\n",
      "        [ 0.2995,  0.4888,  1.2139, -0.8386, -2.1568],\n",
      "        [-0.3760, -0.6604, -0.9275, -0.9795,  0.1738],\n",
      "        [-0.0466, -1.0288,  1.3885, -0.2054,  0.3562],\n",
      "        [ 1.0587,  0.2152,  1.4385, -0.0866,  0.0619],\n",
      "        [ 0.3199, -1.0073, -1.7728, -0.2786, -0.6915],\n",
      "        [-0.1770, -0.0091, -1.4486, -2.2089, -0.1305],\n",
      "        [ 1.4331,  1.1388,  0.4646,  0.9869, -0.4843],\n",
      "        [ 0.9769, -0.0510, -2.1711,  1.5506, -0.9076],\n",
      "        [ 1.2292, -0.9758, -0.8578,  1.2838, -0.2950],\n",
      "        [ 2.0664,  0.2368,  0.4758, -0.9208,  0.0566],\n",
      "        [-0.5976,  0.9428,  0.2625,  0.2948,  1.5380],\n",
      "        [ 1.7554,  2.9009, -1.5138, -1.0331, -0.0969]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "\n",
      "tensor([[ 5.5749e-01, -7.8865e-01, -2.7708e-01, -2.3291e-01, -8.4945e-01],\n",
      "        [ 8.6496e-01, -5.7140e-01,  7.0726e-01,  7.8882e-01, -1.7719e-01],\n",
      "        [-1.6145e+00,  1.5740e+00,  8.4797e-01,  1.4900e+00,  1.1565e+00],\n",
      "        [ 7.4716e-01,  3.5394e-01, -1.1747e+00, -3.9227e-01,  2.6282e-01],\n",
      "        [-3.0013e-01,  1.3144e+00, -1.4894e+00, -9.5025e-01,  2.4090e-01],\n",
      "        [ 2.6156e-01, -4.8745e-01, -1.9803e+00, -5.2558e-01, -3.3934e-01],\n",
      "        [-3.7603e-01, -6.6041e-01, -9.2754e-01, -9.7947e-01,  1.7383e-01],\n",
      "        [ 1.4331e+00,  1.1388e+00,  4.6457e-01,  9.8689e-01, -4.8434e-01],\n",
      "        [-7.8121e-01, -8.6047e-01, -9.7368e-01, -2.5351e-01,  1.7612e+00],\n",
      "        [-1.2614e+00,  6.2510e-01, -6.1864e-03, -9.9082e-01,  2.4444e-01],\n",
      "        [ 3.2274e-02,  9.6317e-01,  9.4629e-02, -5.4242e-02,  2.0168e+00],\n",
      "        [ 3.1986e-01, -1.0073e+00, -1.7728e+00, -2.7856e-01, -6.9147e-01],\n",
      "        [ 9.4840e-03, -5.1125e-01,  1.2272e+00,  4.8869e-01, -1.5583e-01],\n",
      "        [ 8.3534e-01, -7.9056e-01,  8.9364e-01, -7.1611e-01, -5.6487e-01],\n",
      "        [-1.2614e+00,  6.2510e-01, -6.1864e-03, -9.9082e-01,  2.4444e-01],\n",
      "        [-1.6274e+00,  1.5597e+00,  5.1568e-03, -3.4980e-01,  1.0510e+00],\n",
      "        [ 1.5643e+00,  3.5416e-01, -1.7101e+00,  1.5012e+00,  7.3812e-01],\n",
      "        [ 7.9726e-01, -8.8435e-01, -1.8123e-01,  1.1152e+00, -1.3737e+00],\n",
      "        [ 4.0415e-01,  8.1455e-01,  3.1473e-01,  6.4095e-01,  7.2996e-01],\n",
      "        [-5.9763e-01,  9.4276e-01,  2.6251e-01,  2.9478e-01,  1.5380e+00],\n",
      "        [ 9.7195e-01,  1.4215e+00, -1.3600e+00, -6.4110e-01,  6.3072e-02],\n",
      "        [ 1.7642e+00,  1.1814e-02, -4.0907e-01,  2.0425e-01, -7.9626e-01],\n",
      "        [-3.7603e-01, -6.6041e-01, -9.2754e-01, -9.7947e-01,  1.7383e-01],\n",
      "        [ 8.4703e-01, -1.0473e+00, -1.2109e+00, -4.6206e-01, -1.2964e+00],\n",
      "        [-3.5663e-01, -1.2367e+00, -8.0546e-02, -1.4563e+00, -8.8925e-01],\n",
      "        [ 2.7980e-02,  1.5396e+00,  4.8366e-01, -2.8189e-01,  6.3046e-01],\n",
      "        [-3.1332e-01,  4.6173e-01, -1.2974e-03, -5.9138e-01, -1.1157e+00],\n",
      "        [ 2.7980e-02,  1.5396e+00,  4.8366e-01, -2.8189e-01,  6.3046e-01],\n",
      "        [ 2.4279e+00,  7.2844e-01, -1.1541e+00, -1.4465e+00, -3.3209e-01],\n",
      "        [-8.1148e-01, -2.9052e-01,  4.1384e-01,  6.9344e-01,  9.2486e-01],\n",
      "        [ 7.4716e-01,  3.5394e-01, -1.1747e+00, -3.9227e-01,  2.6282e-01],\n",
      "        [-3.9693e-01, -1.1982e+00, -3.1925e-01,  6.7140e-01, -1.0935e+00],\n",
      "        [ 1.1184e+00, -1.5989e+00, -8.3088e-01,  8.9856e-01, -7.9645e-01],\n",
      "        [ 2.7980e-02,  1.5396e+00,  4.8366e-01, -2.8189e-01,  6.3046e-01],\n",
      "        [ 5.6744e-01, -3.5292e-01,  7.8819e-01,  1.1218e+00, -1.2882e-01],\n",
      "        [-2.2035e+00,  1.7369e+00,  2.7274e-01, -7.4258e-01, -2.7884e-01],\n",
      "        [-6.6602e-02,  3.9286e-01,  1.1455e+00,  6.9495e-01, -1.2208e+00],\n",
      "        [-1.2850e+00,  1.7448e+00,  1.2905e+00,  4.4677e-03, -2.0844e+00],\n",
      "        [-5.9763e-01,  9.4276e-01,  2.6251e-01,  2.9478e-01,  1.5380e+00],\n",
      "        [ 1.7554e+00,  2.9009e+00, -1.5138e+00, -1.0331e+00, -9.6869e-02]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "\n",
      "tensor([[ 0.5575, -0.7886, -0.2771, -0.2329, -0.8495],\n",
      "        [-0.7249,  1.0205,  0.1677, -1.1766, -1.3904],\n",
      "        [ 0.0280,  1.5396,  0.4837, -0.2819,  0.6305],\n",
      "        [-1.9860, -1.5700, -2.4628,  0.4217,  0.3466],\n",
      "        [ 0.3199, -1.0073, -1.7728, -0.2786, -0.6915],\n",
      "        [-1.0026, -0.1384, -0.2587, -0.2327, -2.1951],\n",
      "        [-0.0034,  2.8148, -1.7367, -0.4962, -1.3859],\n",
      "        [ 0.8522, -0.6391,  0.5336, -1.2974, -2.0766],\n",
      "        [ 0.0280,  1.5396,  0.4837, -0.2819,  0.6305],\n",
      "        [-0.3760, -0.6604, -0.9275, -0.9795,  0.1738],\n",
      "        [ 1.3088,  0.5007,  0.3974,  0.1418, -0.3609],\n",
      "        [ 0.7973, -0.8844, -0.1812,  1.1152, -1.3737],\n",
      "        [-1.6951, -0.4668,  0.2565,  0.0874, -1.1864],\n",
      "        [-0.3566, -1.2367, -0.0805, -1.4563, -0.8893],\n",
      "        [ 0.7973, -0.8844, -0.1812,  1.1152, -1.3737],\n",
      "        [-1.3572, -0.3428, -1.3677,  1.4083, -1.7648],\n",
      "        [-0.0644,  0.1002,  2.0149, -0.6632, -0.1396],\n",
      "        [ 1.5129,  0.5896,  0.8004,  0.3191,  0.0141],\n",
      "        [ 0.0280,  1.5396,  0.4837, -0.2819,  0.6305],\n",
      "        [ 0.4024, -0.4991,  0.0372, -0.5000,  0.0303],\n",
      "        [-0.3760, -0.6604, -0.9275, -0.9795,  0.1738],\n",
      "        [ 1.1981,  0.0075,  1.2374, -0.4078, -1.2617],\n",
      "        [ 0.2995,  0.4888,  1.2139, -0.8386, -2.1568],\n",
      "        [ 1.4331,  1.1388,  0.4646,  0.9869, -0.4843],\n",
      "        [ 1.5795,  1.0090,  0.8974, -0.6838,  0.9640],\n",
      "        [-0.8940, -0.1888, -1.0472, -0.4511,  0.3125],\n",
      "        [-0.8073, -1.5076, -0.7308, -0.0428,  1.0486],\n",
      "        [-0.4924,  0.2970,  0.2709, -0.1747,  1.6742],\n",
      "        [ 1.4331,  1.1388,  0.4646,  0.9869, -0.4843],\n",
      "        [ 2.2850,  0.8938,  0.6752,  0.0964, -1.1139],\n",
      "        [-0.8940, -0.1888, -1.0472, -0.4511,  0.3125],\n",
      "        [-0.0127, -0.9481, -1.2265,  0.6883, -1.8225],\n",
      "        [-0.3680,  0.3122, -1.5070,  0.1653, -1.0258],\n",
      "        [ 1.0587,  0.2152,  1.4385, -0.0866,  0.0619],\n",
      "        [-1.9381, -0.2130,  0.3329, -1.5939, -2.2390],\n",
      "        [-1.2850,  1.7448,  1.2905,  0.0045, -2.0844],\n",
      "        [-1.1739, -1.5941, -0.4089,  0.9638,  0.8160],\n",
      "        [-0.5976,  0.9428,  0.2625,  0.2948,  1.5380],\n",
      "        [ 1.7554,  2.9009, -1.5138, -1.0331, -0.0969]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reload_modules()\n",
    "print(\"This is the implementation of transformer from scratch in PyTorch.........!!\")\n",
    "tokenizer = Tokenizer()\n",
    "data_loader = DataLoader(\n",
    "    tokenize_source=tokenizer.tokenize_source,\n",
    "    tokenize_target=tokenizer.tokenize_target\n",
    ")\n",
    "train_set,valid_set,test_set = data_loader.make_dataset(es,en)\n",
    "vocab_src,vocab_trg = data_loader.build_vocab(train_set,valid_set,test_set)\n",
    "for word,index in vocab_trg.get_stoi().items():\n",
    "    if index < 10:\n",
    "        print(word,index)\n",
    "# print(f\"Tokenized source example: {tokenizer.tokenize_source('Mi nombre es Bimal !! @ 1 23 * ;.')}\")\n",
    "# print(f\"Tokenized target example: {tokenizer.tokenize_target('My name is Bimal !! @ 1 23 * ;.')}\")\n",
    "# print(f\"Dataset examples: {data_loader.make_dataset(['Mi nombre es Bimal !! @ 1 23 * ;.'],['My name is Bimal !! @ 1 23 * ;.'])}\")\n",
    "# s_tr,s_v,s_te = data_loader.make_dataset(['Mi nombre ','es Bimal !!','@ 1 23 * ;.'],['My name','is Bimal !!','@ 1 23 * ;.'])\n",
    "# print(\"train\",s_tr,\"val\",s_v,\"test\",s_te)\n",
    "# s_v,s_t = data_loader.build_vocab(s_tr,s_v,s_te)\n",
    "# print(s_v.get_stoi())\n",
    "# print(s_t.get_stoi())\n",
    "# print(\"Source vobularies:\",vocab_src)\n",
    "embed = nn.Embedding(len(vocab_src),5)\n",
    "# print(embed(torch.tensor([s_v.get_stoi()['Bimal'],s_v.get_stoi()['nombre']])))\n",
    "# print(embed(torch.tensor(vocab_src.get_stoi()['víctimas'])))\n",
    "for tr in train_set[0:2]:\n",
    "    source_data = torch.tensor(vocab_src(tr[\"src\"]))\n",
    "    target_data = torch.tensor(vocab_trg(tr[\"trg\"]))\n",
    "    print(f\"{embed(source_data)}\\n\")\n",
    "    print(f\"{embed(target_data)}\\n\")\n",
    "# print(embed(torch.tensor(vocab_src(train_set[0][\"src\"]))))\n",
    "# print(embed(torch.tensor(vocab_trg(train_set[0][\"trg\"]))))\n",
    "# print(len(train_set[0][\"src\"]))\n",
    "# print(len(train_set[0][\"trg\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7453ead9-cb25-4ff2-a85b-6bdea2cf9a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([[-0.3957, -0.7917, -0.8854, -1.0388,  0.2935],\n",
      "        [ 0.3695,  1.1772, -0.1016, -0.0530,  2.9675]]);\n",
      " Weights: Parameter containing:\n",
      "tensor([[ 0.3889,  0.2105, -0.3361,  0.2118,  0.3607],\n",
      "        [ 0.0708, -0.0097, -0.3159,  0.0255,  0.0843],\n",
      "        [ 0.0622, -0.0502, -0.1573,  0.2903, -0.3261],\n",
      "        [ 0.1617, -0.2933, -0.4009,  0.0485, -0.2035],\n",
      "        [ 0.2871,  0.1391,  0.1093,  0.3671,  0.4233]], requires_grad=True) \n",
      " Bias:Parameter containing:\n",
      "tensor([ 0.3889, -0.3022, -0.0681,  0.0988, -0.2972], requires_grad=True) \n",
      " After transformation: tensor([[ 0.2518, -0.0446, -0.3110,  0.5119, -0.8748],\n",
      "        [ 1.8737, -0.0066, -1.0713, -0.7525,  1.1983]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m =  nn.Linear(5,5)\n",
    "input = torch.randn(2,5)\n",
    "print(f\"Input: {input};\\n Weights: {m.weight} \\n Bias:{m.bias} \\n After transformation: {m(input)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b7c627-cfb2-480d-88c8-2fd88c30e247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xA^T + b\n",
      "tensor([[ 0.0317,  1.0852, -0.1520,  0.2692,  1.0627],\n",
      "        [-0.4348,  0.2320,  0.5764, -0.3571, -0.0219]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"xA^T + b\") # This transformation applies after the nn.Linear is applied.\n",
    "x = torch.tensor([[-0.3074,  1.5631,  0.5804, -1.0671, -0.6132],\n",
    "        [-0.1582, -0.2556, -0.1892,  0.0084,  0.7520]])\n",
    "w = torch.tensor([[-0.1351,  0.0465,  0.2974,  0.0119, -0.1067],\n",
    "        [-0.2380,  0.2958,  0.1583,  0.0208, -0.1320],\n",
    "        [-0.3229, -0.1220, -0.2476,  0.1831,  0.1225],\n",
    "        [ 0.0242,  0.0074,  0.0925, -0.2421, -0.2087],\n",
    "        [ 0.2182, -0.0354,  0.2494, -0.3794, -0.4260]])\n",
    "b = torch.tensor([-0.3079,  0.3990,  0.3536, -0.1749,  0.3743])\n",
    "a = x @ w.t()\n",
    "o = a + b\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a86204-016e-4bd3-a258-1f54be028521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attention scores of of the first sentence in our dataset\n",
      "\n",
      "Query, Key and Value shape: torch.Size([40, 5])\n",
      "torch.Size([40, 40])\n"
     ]
    }
   ],
   "source": [
    "from models.scaled_dot_product_attention import ScaledDotProductAttention\n",
    "print(f\"The attention scores of of the first sentence in our dataset\\n\")\n",
    "first_sentence_src = train_set[0][\"src\"]\n",
    "first_sen_embed_src = embed(torch.tensor(vocab_src(first_sentence_src)))\n",
    "print(f\"Query, Key and Value shape: {first_sen_embed_src.shape}\")\n",
    "scaled_attn = ScaledDotProductAttention(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3b681-5b63-4e74-98e2-53d2e276e423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualise_attention_scores(scores,words,vocab_type):\n",
    "    scores_np = scores.detach().numpy()\n",
    "    plt.figure(figsize=(18,8))\n",
    "    sns.heatmap(scores_np,xticklabels=words,yticklabels=words,annot=True,fmt='.1f',cmap=\"Blues\")\n",
    "    plt.title(f\"Attention scores visualization for Query and Key of first sentence of {vocab_type}\")\n",
    "    plt.xlabel(\"Keys\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7841593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scores to numpy for visualization\n",
    "scores = scaled_attn.query_key_attention(first_sen_embed_src,first_sen_embed_src,False)\n",
    "print(scores.shape)\n",
    "visualise_attention_scores(scores,first_sentence_src,\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5db994",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_scores = scaled_attn.query_key_attention(first_sen_embed_src,first_sen_embed_src,True)\n",
    "# This is scaled attention scores\n",
    "print(scaled_scores)\n",
    "visualise_attention_scores(scaled_scores,first_sentence_src,\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f8781",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = scaled_attn.forward(first_sen_embed_src,first_sen_embed_src,first_sen_embed_src)\n",
    "print(attention.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
