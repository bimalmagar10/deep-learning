{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0687015-483f-4acb-848a-2f93efe7d510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized from jupyter or other except terminal or command prompt script!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'models.nn' from '/Users/bimalmgr/Downloads/deep_learning/transformers/trnsfmr_from_scratch/models/nn.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils.data_loader\n",
    "import utils.tokenize\n",
    "import models.embedding\n",
    "import models.nn\n",
    "\n",
    "#For reloading\n",
    "importlib.reload(utils.data_loader)\n",
    "importlib.reload(utils.tokenize)\n",
    "importlib.reload(models.embedding)\n",
    "importlib.reload(models.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04707c00-2a11-45c3-9b67-addcea9612d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import DataLoader\n",
    "from utils.tokenize import Tokenizer\n",
    "from data import en,es\n",
    "from models.embedding import Embeddings\n",
    "from data import en,es\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c5d510d-f35b-4fce-871c-e8f5670499ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_modules():\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2693b3b3-699c-46a5-96dc-7bcbb04dccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the implementation of transformer from scratch in PyTorch.........!!\n",
      "Initializing the data loader........\n",
      "train [{'src': ['<sos>', 'Mi', 'nombre', '<eos>'], 'trg': ['<sos>', 'My', 'name', '<eos>']}, {'src': ['<sos>', 'es', 'Bimal', '!', '!', '<eos>'], 'trg': ['<sos>', 'is', 'Bimal', '!', '!', '<eos>']}] val [] test [{'src': ['<sos>', '@', '1', '23', '*', ';', '.', '<eos>'], 'trg': ['<sos>', '@', '1', '23', '*', ';', '.', '<eos>']}]\n",
      "Building Spanish Vocabulary.....\n",
      "Done Building Spanish Vocabulary!\n",
      "Buidling English Vocabulary.........\n",
      "Done building English Vocabulary!\n",
      "{'Bimal': 11, '23': 8, '1': 7, '.': 6, 'es': 13, '*': 5, '!': 4, ';': 9, '<sos>': 2, 'nombre': 14, 'Mi': 12, '@': 10, '<eos>': 3, '<pad>': 1, '<unk>': 0}\n",
      "{'is': 13, 'Bimal': 11, '23': 8, '1': 7, 'name': 14, '.': 6, '*': 5, '!': 4, ';': 9, '<sos>': 2, '@': 10, '<eos>': 3, 'My': 12, '<pad>': 1, '<unk>': 0}\n",
      "tensor([[ 1.6507, -0.7271,  0.1678, -2.0592, -0.4729],\n",
      "        [-0.3511, -0.5692, -0.3795,  0.8179,  0.8439]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "reload_modules()\n",
    "print(\"This is the implementation of transformer from scratch in PyTorch.........!!\")\n",
    "tokenizer = Tokenizer()\n",
    "data_loader = DataLoader(\n",
    "    tokenize_source=tokenizer.tokenize_source,\n",
    "    tokenize_target=tokenizer.tokenize_target\n",
    ")\n",
    "# train_set,valid_set,test_set = data_loader.make_dataset(es,en)\n",
    "# vocab_src,vocab_trg = data_loader.build_vocab(train_set,valid_set,test_set)\n",
    "# for word,index in vocab_trg.get_stoi().items():\n",
    "#     print(word,index)\n",
    "# print(f\"Tokenized source example: {tokenizer.tokenize_source('Mi nombre es Bimal !! @ 1 23 * ;.')}\")\n",
    "# print(f\"Tokenized target example: {tokenizer.tokenize_target('My name is Bimal !! @ 1 23 * ;.')}\")\n",
    "# print(f\"Dataset examples: {data_loader.make_dataset(['Mi nombre es Bimal !! @ 1 23 * ;.'],['My name is Bimal !! @ 1 23 * ;.'])}\")\n",
    "s_tr,s_v,s_te = data_loader.make_dataset(['Mi nombre ','es Bimal !!','@ 1 23 * ;.'],['My name','is Bimal !!','@ 1 23 * ;.'])\n",
    "print(\"train\",s_tr,\"val\",s_v,\"test\",s_te)\n",
    "s_v,s_t = data_loader.build_vocab(s_tr,s_v,s_te)\n",
    "print(s_v.get_stoi())\n",
    "print(s_t.get_stoi())\n",
    "# print(\"Source vobularies:\",vocab_src)\n",
    "embed = nn.Embedding(len(s_v),5)\n",
    "print(embed(torch.tensor([s_v.get_stoi()['Bimal'],s_v.get_stoi()['nombre']])))\n",
    "# print(embed(torch.tensor(vocab_src.get_stoi()['v√≠ctimas'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7453ead9-cb25-4ff2-a85b-6bdea2cf9a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([[-0.6032, -0.1903, -0.0376,  2.1739,  0.7048],\n",
      "        [ 1.1337, -1.0121, -0.0053,  0.7635, -0.6674]]);\n",
      " Weights: Parameter containing:\n",
      "tensor([[-0.4285, -0.1749,  0.3861,  0.1003, -0.0440],\n",
      "        [-0.3463,  0.3087, -0.0713, -0.2879,  0.1215],\n",
      "        [-0.3353, -0.1929,  0.2763, -0.2470,  0.3143],\n",
      "        [-0.3104,  0.0472, -0.3150, -0.1126, -0.2413],\n",
      "        [ 0.0214,  0.4337, -0.2485, -0.4455, -0.0150]], requires_grad=True) \n",
      " Bias:Parameter containing:\n",
      "tensor([ 0.3792,  0.0900, -0.0541,  0.3431, -0.0840], requires_grad=True) \n",
      " After transformation: tensor([[ 0.8436, -0.2974, -0.1409,  0.1184, -1.1492],\n",
      "        [ 0.1745, -0.9155, -0.6388,  0.0202, -0.8275]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m =  nn.Linear(5,5)\n",
    "input = torch.randn(2,5)\n",
    "print(f\"Input: {input};\\n Weights: {m.weight} \\n Bias:{m.bias} \\n After transformation: {m(input)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b7c627-cfb2-480d-88c8-2fd88c30e247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xA^T + b\n",
      "tensor([[ 0.0317,  1.0852, -0.1520,  0.2692,  1.0627],\n",
      "        [-0.4348,  0.2320,  0.5764, -0.3571, -0.0219]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"xA^T + b\") # This transformation applies after the nn.Linear is applied.\n",
    "x = torch.tensor([[-0.3074,  1.5631,  0.5804, -1.0671, -0.6132],\n",
    "        [-0.1582, -0.2556, -0.1892,  0.0084,  0.7520]])\n",
    "w = torch.tensor([[-0.1351,  0.0465,  0.2974,  0.0119, -0.1067],\n",
    "        [-0.2380,  0.2958,  0.1583,  0.0208, -0.1320],\n",
    "        [-0.3229, -0.1220, -0.2476,  0.1831,  0.1225],\n",
    "        [ 0.0242,  0.0074,  0.0925, -0.2421, -0.2087],\n",
    "        [ 0.2182, -0.0354,  0.2494, -0.3794, -0.4260]])\n",
    "b = torch.tensor([-0.3079,  0.3990,  0.3536, -0.1749,  0.3743])\n",
    "a = x @ w.t()\n",
    "o = a + b\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a86204-016e-4bd3-a258-1f54be028521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.scaled_dot_product_attention import ScaledDotProductAttention\n",
    "\n",
    "embedded_bimal = embed(torch.tensor([s_v.get_stoi()['Bimal'],s_v.get_stoi()['My']]))\n",
    "scaled_attention = ScaledDotProductAttention(5)\n",
    "print(scaled_attention.forward(embedded_bimal,embedded_bimal,embedded_bimal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ab502c2-f496-4bf8-b68d-0e0332ec79f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the full implementation of transformers from scratch in pytorch\n"
     ]
    }
   ],
   "source": [
    "print(f\"This is the full implementation of transformers from scratch in pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d7df0a-6533-4d97-97cb-b00a228e4a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
